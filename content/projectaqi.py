# -*- coding: utf-8 -*-
"""ProjectAQI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hhg74RMMDYeMim-6oLjLAcn3gDU9ieNh
"""



import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

data=pd.read_csv("/content/data.csv")
data

data.info()

# Clean column names
data.columns = data.columns.str.strip().str.lower()

# Ensure pollutant values are floats
for col in ['pm25', 'pm10', 'o3', 'no2', 'so2', 'co']:
    if col in data.columns:
        data[col] = (
            data[col]
            .astype(str)                           # convert to string
            .str.extract(r'([\d\.]+)')[0]           # extract numeric part
            .astype(float)                          # convert to float
        )
data['date'] = pd.to_datetime(data['date'],format='mixed')

data.info()

data.describe()

data.isna().sum()

data['city'].unique()

# Encode 'city'



# Extract features from 'date'
data['day'] = data['date'].dt.day
data['month'] = data['date'].dt.month
data['year'] = data['date'].dt.year

# Drop 'date' if not needed anymore

data['year'].value_counts().sort_index()

'''year_counts.plot(kind='bar', title='Data Entries per Year')
plt.xlabel('Year')
plt.ylabel('Number of Rows')
plt.tight_layout()
plt.show()
'''

data = data[~data['year'].isin([2015,2016,2017,2018,])]

data['year'].value_counts().sort_index()

city_counts = data['city'].value_counts()
plt.pie(city_counts, labels=city_counts.index, autopct='%1.1f%%', shadow=True)
plt.title('City Distribution')
plt.axis('equal')  #
plt.show()
print(city_counts)

sns.scatterplot(x='city', y='pm10', data=data,hue='pm10')
  plt.xticks(rotation =90)

sns.scatterplot(x='city', y='pm25', data=data,hue='pm25')
  plt.xticks(rotation =90)

#sns.pairplot(hue="city",data=data)

for col in['pm25', 'pm10', 'o3', 'no2', 'so2', 'co']:
   for city in data['city'].unique():
      med_val = data[data['city'] == city][col].median()
      data.loc[
          (data['city'] == city) & (data[col].isnull()),
          col
      ] = med_val

data.isna().sum()

sns.histplot(data= data[data["city"] == "thiruvananthapuram"], x="pm25", kde=True)
plt.title("Distribution of PM25 in Thiruvananthapuram")
plt.xlabel("PM25")
plt.ylabel("Frequency")
plt.show()

plt.figure(figsize=(8,6))
sns.boxplot(data)
plt.title("Boxplot")
plt.show()

cols = ['pm25', 'pm10', 'o3', 'no2', 'so2', 'co']
for col in cols:
  plt.figure(figsize=(12, 6))
  sns.boxplot(x='city', y=col, data=data)
  plt.title(f"{col} by City")
  plt.xticks(rotation=90)
  plt.show()

cols = ['pm25', 'pm10', 'o3', 'no2', 'so2', 'co']

for col in cols:
    for city in data['city'].unique():
        city_data = data[data['city'] == city][col]

        Q1 = city_data.quantile(0.25)
        Q3 = city_data.quantile(0.75)   # ✅ Use 0.75, not 0.74
        IQR = Q3 - Q1

        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        data.loc[data['city'] == city, col] = city_data.clip(lower_bound, upper_bound)

cols = ['pm25', 'pm10', 'o3', 'no2', 'so2', 'co']
for col in cols:
  plt.figure(figsize=(12, 6))
  sns.boxplot(x='city', y=col, data=data)
  plt.title(f"{col} by each City")
  plt.xticks(rotation=90)
  plt.show()

data

data.drop_duplicates(inplace=True)

data



# Define breakpoint tables for each pollutant (CPCB India standard)
breakpoints = {
    'pm25': [
        (0, 30, 0, 50), (31, 60, 51, 100), (61, 90, 101, 200),
        (91, 120, 201, 300), (121, 250, 301, 400), (251, 350, 401, 500)
    ],
    'pm10': [
        (0, 50, 0, 50), (51, 100, 51, 100), (101, 250, 101, 200),
        (251, 350, 201, 300), (351, 430, 301, 400), (431, 500, 401, 500)
    ],
    'o3': [
        (0, 50, 0, 50), (51, 100, 51, 100), (101, 168, 101, 200),
        (169, 208, 201, 300), (209, 748, 301, 400), (749, 1000, 401, 500)
    ],
    'no2': [
        (0, 40, 0, 50), (41, 80, 51, 100), (81, 180, 101, 200),
        (181, 280, 201, 300), (281, 400, 301, 400), (401, 500, 401, 500)
    ],
    'so2': [
        (0, 40, 0, 50), (41, 80, 51, 100), (81, 380, 101, 200),
        (381, 800, 201, 300), (801, 1600, 301, 400), (1601, 2000, 401, 500)
    ],
    'co': [
        (0, 1, 0, 50), (1.1, 2, 51, 100), (2.1, 10, 101, 200),
        (10.1, 17, 201, 300), (17.1, 34, 301, 400), (34.1, 50, 401, 500)
    ]
}

def calc_subindex(pollutant, value):
    for bp_low, bp_high, index_low, index_high in breakpoints[pollutant]:
        if bp_low <= value <= bp_high:
            return ((index_high - index_low) / (bp_high - bp_low)) * (value - bp_low) + index_low
    return None  # Out of range

# Apply to each row
aqi_values = []
for i, row in data.iterrows():
    sub_indices = {}
    for pollutant in ['pm25', 'pm10', 'o3', 'no2', 'so2', 'co']:
        if pollutant in row and pd.notna(row[pollutant]):
            value = row[pollutant]
            print(f"{pollutant}: {value}")
            sub_index = calc_subindex(pollutant, value)
            if sub_index is not None:
                sub_indices[pollutant] = round(sub_index)
    aqi = max(sub_indices.values()) if sub_indices else None
    print(f"{max(sub_indices.values()) if sub_indices else None}: {aqi}")
    aqi_values.append(aqi)

# Assign back
data["aqi"] = aqi_values

#data["AQI"] = data.apply(calculate_aqi, axis=1)


print("✅ AQI calculated and saved to aqi_output.csv")

data

sns.scatterplot(x='city', y='aqi', data=data,hue='aqi')
plt.xticks(rotation =90)
plt.axhline(100, color='green', linestyle='--', label='Moderate')
plt.axhline(200, color='orange', linestyle='--', label='Unhealthy')
plt.legend()

"""Let's start by visualizing the distribution of AQI values using a histogram.

plt.plot(data['city'== 'thiruvananthapuram'],data['aqi'],"g,--",marker='o')
plt.xticks(ticks= range(1, 25,1),rotation =45)
plt.title("Model Accuracy vs K Value")
plt.xlabel("K value")
plt.ylabel("Accuracy")
plt.grid()
plt.show()
"""

plt.figure(figsize=(10, 6))
sns.histplot(data['aqi'], bins=50, kde=True)
plt.title('Distribution of AQI Values')
plt.xlabel('AQI')
plt.ylabel('Frequency')
plt.show()

"""Now, let's visualize the AQI over time for a few selected cities. We'll need to convert the 'date' column to datetime objects first."""

data['date'] = pd.to_datetime(data['date'], format='%d-%m-%Y', errors='coerce')

# Select a few cities for visualization
selected_cities = data['city'].unique()[:5] # Visualize the first 5 cities

plt.figure(figsize=(15, 8))
for city in selected_cities:
    city_data = data[data['city'] == city].sort_values('date')
    plt.plot(city_data['date'], city_data['aqi'], label=city)

plt.title('AQI over Time for Selected Cities')
plt.xlabel('Date')
plt.ylabel('AQI')
plt.legend()
plt.grid(True)
plt.show()

def get_aqi_category(aqi):
    if pd.isna(aqi):
        return np.nan
    elif aqi <= 50:
        return 'Good'
    elif aqi <= 100:
        return 'Moderate'
    elif aqi <= 150:
        return 'Unhealthy for Sensitive Groups'
    elif aqi <= 200:
        return 'Unhealthy'
    elif aqi <= 300:
        return 'Very Unhealthy'
    else:
        return 'Hazardous'

data

#data["aqi_category"].value_counts()

data.info()

# Features to scale
scale_cols = ['pm25', 'pm10', 'o3', 'no2', 'so2', 'co', 'day', 'month', 'year']
sd = StandardScaler()
data_sc = data.copy()
data_sc[cols] = sd.fit_transform(data[cols])

#x['city'] = LabelEncoder().fit_transform(x['city'])

from prophet import Prophet

data

df_city = data[data['city'] == 'delhi'][['date', 'aqi']].copy()
df_city = df_city.rename(columns={'date': 'ds', 'aqi': 'y'})
df_city

# Set date as index and reindex to all dates
  # force daily freq
df_city = df_city.set_index('ds').asfreq('D')
df_city['y'] = df_city['y'].interpolate()      # fill missing AQI values if needed
df_city = df_city.reset_index()
df_city

model = Prophet()
model.fit(df_city)

df_city

model = Prophet()

model.fit(df_city)

future = model.make_future_dataframe(periods=30)

# Predict
forecast = model.predict(future)

# Plot
model.plot(forecast)

forecast

aqid = forecast[forecast['ds'] == '2025-08-20']
aqid

user_input = input("Enter a date (YYYY-MM-DD): ")
input_date = pd.to_datetime(user_input)

# --- Step 4: Look up prediction for that date ---
result = forecast[forecast['ds'] == input_date]

# ✅ Assuming your DataFrame is already named `data`
# And has columns: 'city', 'date', 'aqi'

# 🛠️ Take input from user
city_input = input("Enter city name: ").strip()
date_input = input("Enter date to predict (YYYY-MM-DD): ").strip()

# ✅ Filter city data and prepare for Prophet
df_city = data[data['city'].str.lower() == city_input.lower()][['date', 'aqi']].copy()
df_city = df_city.rename(columns={'date': 'ds', 'aqi': 'y'})
df_city = df_city.set_index('ds').asfreq('D')  # force daily freq
df_city['y'] = df_city['y'].interpolate()      # fill missing AQI values if needed
df_city = df_city.reset_index()


# 🧠 Train Prophet
model = Prophet()
model.fit(df_city)

# 📅 Make future dataframe
future = model.make_future_dataframe(periods=60)
forecast = model.predict(future)

# 🔍 Find prediction for the input date
target = forecast[forecast['ds'] == pd.to_datetime(date_input)]
print(target,"this s")
if not target.empty:
    predicted_aqi = round(target['yhat'].values[0], 2)
    get_aqi_category(predicted_aqi)
    # 🟢 Convert AQI to category


    print(f"\n📍 Predicted AQI for {city_input.title()} on {date_input}: {predicted_aqi}")
    print(f"🧾 AQI Category: {get_aqi_category(predicted_aqi)}")
else:
    print("⚠️ Date out of range or invalid. Try a date within ~30–60 days from the last available data.")


fig2 = model.plot_components(forecast)

